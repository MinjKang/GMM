import warnings; warnings.simplefilter('ignore')
import pandas as pd
import numpy as np
from numpy import quantile, where
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
import missingno as msno

dataset = pd.read_csv("sensor.csv")
dataset = dataset.fillna(0)
dataset.head(5)

datatime = dataset["timestamp"]
del dataset["timestamp"]

del dataset["Unnamed: 0"]

dataset

dataset.loc[dataset["machine_status"]== 'NORMAL', 'class'] = '1' #정상
dataset.loc[dataset["machine_status"]== 'RECOVERING', 'class'] = '0' #이상
dataset.loc[dataset["machine_status"]== 'BROCKEN', 'class'] = '0' #이상

del dataset['machine_status']

# Plot the balance of class labels
normal = dataset['class']
df_base = dataset.copy()

print('1 = normal, 0 = abnormal')
value_counts = normal.value_counts()
print(value_counts)

plt.figure(figsize=(16,2))
fig = sns.countplot(y=normal, data=dataset, color='b')
plt.show()

train_dataset = dataset['class'].isin(['1'])
train_dataset = dataset.loc[train_dataset]

test_dataset_normal = train_dataset.iloc[191359:]
train_dataset = train_dataset.iloc[:191359]

test_dataset = dataset['class'].isin(['0'])
test_dataset = dataset.loc[test_dataset]

test_dataset = pd.concat([test_dataset_normal, test_dataset])

train_dataset.shape, test_dataset.shape, test_dataset_normal.shape

y_train = train_dataset["class"]
y_test = test_dataset["class"]

del train_dataset['class']
del test_dataset['class']

plt.figure(figsize=(16,2))
fig = sns.countplot(y=y_train, data=y_train, color='b')
plt.show()

plt.figure(figsize=(16,2))
fig = sns.countplot(y=y_test, data=y_test, color='b')
plt.show()

from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler

scaler = MinMaxScaler()
X_scaled_train  = scaler.fit_transform(train_dataset)
X_scaled_test  = scaler.fit_transform(test_dataset)



from sklearn.mixture import GaussianMixture

GMM = GaussianMixture(n_components=3, random_state=100)

GMM.fit(train_dataset)

anomaly_score_GMM_train = GMM.score_samples(train_dataset)
anomaly_score_GMM_train

anomaly_score_GMM_sorted = sorted(anomaly_score_GMM_train)

anomaly_score_GMM_test = GMM.score_samples(test_dataset)
anomaly_score_GMM_test.shape

error = np.array(anomaly_score_GMM_sorted)     
error = error.reshape(-1,1)

error_test=np.array(anomaly_score_GMM_test)
error_test = error_test.reshape(-1,1)

from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler

scaler = MinMaxScaler()
scaled_error  = scaler.fit_transform(error)
scaled_error_test  = scaler.fit_transform(error_test)

thresh_GMM = np.percentile(scaled_error, 90)

# classifier
df_test = []

def novelty_classifier(novelty_score):
    for i in range(len(novelty_score)):
        if novelty_score[i] > thresh_GMM:
            df_test.append('0')
        else:
            df_test.append('1')

novelty_classifier(scaled_error_test)

def measure_performance(model, X_test, y_true, map_labels):
    # predict on testset

    df_pred_test = pd.DataFrame(X_test, columns=['Pred'])
    x_pred = df_pred_test['Pred'] 
    
    matrix = confusion_matrix(x_pred, y_true)

    sns.heatmap(pd.DataFrame(matrix, columns = ['Actual', 'Predicted']),
                xticklabels=['Normal [0]', 'Abnormal [1]'], 
                yticklabels=['Normal [0]', 'Abnormal [1]'], 
                annot=True, fmt="d", linewidths=.5, cmap="YlGnBu")
    plt.ylabel('Predicted')
    plt.xlabel('Actual')
    
    print(classification_report(X_test, y_true))
    
    model_score = score(X_test, y_true,average='macro')
    print(f'f1_score: {np.round(model_score[2]*100, 2)}%')
    
    return model_score



map_labels = True 
model_score = measure_performance(GMM, df_test, y_test, map_labels)
performance_df = pd.DataFrame().append({'model_name':GMM, 
                                    'f1_score': model_score[0], 
                                    'precision': model_score[1], 
                                    'recall': model_score[2]}, ignore_index=True)
